## 检查Version下环境
mmcv 1.37-1.40
##  为什么argparse要搞那么麻烦：
###   方便调参，将参数与代码分割
***
### train.py的代码：

```python
1.    args = parse_args(args)

2.    cfg = Config.fromfile(args.config)
    
3.    if args.options is not None:
        cfg.merge_from_ict(args.options)
```

1. 这一行调用了 `parse_args` 函数，传入 `args`（通常是 `sys.argv[1:]`，即命令行中除了脚本名之外的参数）。此函数基于 `argparse` 模块的定义解析命令行参数。
   - 返回值 `args` 是一个包含所有已解析命令行参数的对象，每个参数都作为该对象的一个`属性`
2. `Config.fromfile` (属于 `mmcv` 包) 将配置文件变成 json 文件
   - `cfg` 变量现在包含了配置文件中的所有设置。这些设置通常包括模型参数、训练参数、数据处理方法等。
3. 这个条件判断检查命令行参数中是否提供了 `options`。这个 `options` 参数允许用户在命令行中指定额外的配置选项，通常以键值对的形式传递。
   - `cfg.merge_from_dict(args.options)` 将这些额外的配置选项合并到已加载的配置 `cfg` 中。如果 `cfg` 中已有相同的键，则这些值将被 `args.options` 中的值覆盖。

```python
1.  if cfg.get('cudnn_benchmark', False):
        torch.backends.cudnn.benchmark = True

2.  if args.work_dir is not None:
        cfg.work_dir = args.work_dir
    elif cfg.get('work_dir', None) is None:
        cfg.work_dir = osp.join('./work_dirs', osp.splitext(osp.basename(args.config))[0])

3.  if args.load_from is not None:
        cfg.load_from = args.load_from
    if args.resume_from is not None:
        cfg.resume_from = args.resume_from

4.  if args.gpu_ids is not None:
        cfg.gpu_ids = args.gpu_ids
    else:
        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)
```
1. **设置 CUDNN 基准**：
   - 检查配置中是否启用了 CUDNN 基准（`'cudnn_benchmark'`）。
   - 设置 `torch.backends.cudnn.benchmark=True` 将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。适用场景是网络结构固定（不是动态变化的），网络的输入形状（包括 batch size，图片大小，输入的通道）是不变的，其实也就是一般情况下都比较适用。反之，如果卷积层的设置一直变化，将会导致程序不停地做优化，反而会耗费更多的时间。

2. **确定工作目录**：
   - 检查命令行参数中是否提供了工作目录 (`args.work_dir`)。
   - 如果提供了，使用这个作为工作目录。否则，检查配置文件中是否定义了工作目录。
   - 如果配置文件中也没有定义，那么使用默认工作目录，通常基于配置文件的名称构建路径。

3. **模型加载和恢复配置**：
   - 检查是否通过命令行参数指定了预训练模型的加载路径 (`args.load_from`)。
   - 如果指定了，更新配置以从该路径加载模型。
   - 同样检查是否指定了恢复训练的检查点文件路径 (`args.resume_from`)。
   - 如果指定了，更新配置以从该检查点恢复训练。

4. **GPU 配置**：
   - 检查是否通过命令行参数指定了特定的 GPU ID (`args.gpu_ids`)。
   - 如果指定了，更新配置以使用这些特定的 GPU。
   - 否则，根据是否指定了使用多少个 GPU (`args.gpus`) 来设置 GPU ID。如果没有指定，则默认使用一个 GPU。

```python
1.  if args.launcher == 'none':
        distributed = False
    else:
        distributed = True
        init_dist(args.launcher, **cfg.dist_params)
```

1. **分布式训练设置**：
   - 这部分代码负责初始化分布式训练环境，这是在训练过程中跨多个 GPU 或机器节点进行协同工作的关键设置。
   - 首先，通过 `if args.launcher == 'none':` 检查是否指定了分布式启动器。如果没有指定（即等于 `'none'`），则将 `distributed` 变量设置为 `False`，表示不使用分布式训练。
   - 否则，如果指定了分布式启动器（如 `'pytorch'`、`'slurm'`、`'mpi'` 等），则将 `distributed` 变量设置为 `True` 并调用 `init_dist(args.launcher, **cfg.dist_params)` 来初始化分布式训练环境。这包括根据配置参数设置进程间通信方式、同步策略等。
   - `init_dist` 函数是分布式训练配置的核心，它根据提供的启动器和分布式参数设置相应的环境。

```python
1.  mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))

2.  timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')
    logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)

3.  env_info_dict = collect_env()
    env_info = '\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])
    logger.info('Environment info:\n' + dash_line + env_info + '\n' + dash_line)

4.  if args.seed is not None:
        set_random_seed(args.seed, deterministic=args.deterministic)
```
1. **创建工作目录和配置备份**：
   - `mmcv.mkdir_or_exist` 确保工作目录存在，如果不存在则创建。工作目录用于存放训练过程中生成的文件。
   - `cfg.dump` 将当前配置信息保存在工作目录中，方便未来的复现和审查。

2. **初始化日志记录器**：
   - `time.strftime` 创建一个基于当前时间的时间戳，用于命名日志文件。
   - `osp.join` 构建日志文件的完整路径。
   - `get_root_logger` 初始化日志记录器，设置日志文件路径和日志级别。

3. **收集和记录环境信息**：
   - `collect_env` 收集当前训练环境的详细信息（如操作系统、Python 版本等）。
   - 将环境信息格式化为字符串，并通过日志记录器记录。收集和记录训练环境的详细信息，提高了实验的透明度和可追溯性

4. **设置随机种子**：
   - `deterministic` 参数控制是否启用 PyTorch 的确定性模式，这可以影响到实验的可重复性。

```python
1.  model = build_train_model(cfg, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))

2.  model.init_weights()

3.  datasets = [build_dataset(cfg.data.train)]

4.  if len(cfg.workflow) == 2:
        val_dataset = copy.deepcopy(cfg.data.val)
        val_dataset.pipeline = cfg.data.train.pipeline
        datasets.append(build_dataset(val_dataset))
```

1. **构建训练模型**：
      # 重点
   - `build_train_model` 函数根据配置文件 `cfg` 中的设置构建用于训练的模型。这包括定义模型架构、训练配置 (`train_cfg`) 和测试配置 (`test_cfg`)。
   - 这一步是创建模型对象的关键过程，确保模型符合训练的需求和规格。

2. **初始化模型权重**：
   - `model.init_weights()` 调用初始化模型权重的函数。这个步骤通常涉及加载预训练权重或使用特定的初始化策略（例如随机初始化）。

3. **构建训练数据集**：
   - 使用 `build_dataset` 函数根据配置 `cfg.data.train` 创建训练数据集。这通常包括数据的加载、预处理和增强。

4. **构建验证数据集（如果配置了验证步骤）**：
   - 如果 `cfg.workflow` 的长度为 2，这表示训练流程包括训练和验证两个阶段。
   - 使用 `copy.deepcopy` 创建验证数据配置的副本，以确保训练和验证使用的数据集设置是独立的。
   - 调整验证数据集的 `pipeline` 以与训练数据集一致，然后将其添加到数据集列表中。


### 格式化代码块
```python
1.  if cfg.checkpoint_config is not None:
        cfg.checkpoint_config.meta = dict(
            mmseg_version=f'{__version__}+{get_git_hash()[:7]}',
            config=cfg.pretty_text,
            CLASSES=datasets[0].CLASSES,
            PALETTE=datasets[0].PALETTE)
    model.CLASSES = datasets[0].CLASSES

2.  train_segmentor(
        model,
        datasets,
        cfg,
        distributed=distributed,
        validate=(not args.no_validate),
        timestamp=timestamp,
        meta=meta)
```

1. **配置检查点和模型类别信息**：
   - 检查是否定义了检查点配置 (`cfg.checkpoint_config`)。如果定义了，添加元数据到检查点配置中。
   - 元数据包括 MMsegmentation 版本、当前配置的文本表示、数据集的类别 (`CLASSES`) 和调色板 (`PALETTE`)。
   - 设置模型的 `CLASSES` 属性为当前数据集的类别。这有助于训练过程中正确处理不同的类别。

2. **启动训练过程**：
   - 调用 `train_segmentor` 函数开始模型的训练过程。
   - 传递准备好的模型 (`model`)、数据集 (`datasets`)、配置 (`cfg`)、以及其他关键参数到训练函数。
   - `distributed` 参数指明是否在分布式环境下训练。
   - `validate` 参数决定是否在训练过程中进行验证步骤。
   - `timestamp` 和 `meta` 提供额外的训练上下文信息，如训练开始的时间和环境元数据。